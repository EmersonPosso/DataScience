{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8342228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIVE QUE INSTALAR UMA BIBLIOTECA QUE FALTOU...\n",
    "\n",
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANDO AS BIBLIOTECAS NECESSÁRIAS\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bibliotecas Básicas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Plotagem e Visualização\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "import missingno as msno\n",
    "\n",
    "# Pre-Processamento\n",
    "from tensorflow.keras.preprocessing.image import (ImageDataGenerator, \n",
    "                                       img_to_array, \n",
    "                                       array_to_img, \n",
    "                                       load_img)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             classification_report, \n",
    "                             accuracy_score, \n",
    "                             f1_score, \n",
    "                             roc_auc_score)\n",
    "# Modelando\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# Plotagem do Modelo\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Mesclagem\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8996532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFININDO E CONFERINDO O TAMANHO DE CADA DATASET\n",
    "\n",
    "train_dir = \"C:/Users/Will/Documents/Data_Science/Projeto Final/dogs-vs-cats/train/\"\n",
    "test_dir  = \"C:/Users/Will/Documents/Data_Science/Projeto Final/dogs-vs-cats/test1/\"\n",
    "print(\"Total de imagens no dataset de treino e teste...\")\n",
    "print('\\n' + 'No. de imagens de treino: '+ str(len(os.listdir(train_dir))))\n",
    "print('No. de imagens de testes: ' + str(len(os.listdir(test_dir))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db611131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARMAZENANDO AS IMAGENS EM DATAFRAMES\n",
    "\n",
    "def category(path): \n",
    "    return [file.split('.')[0] for file in os.listdir(path)]\n",
    "\n",
    "def filename(path):\n",
    "    return [file for file in os.listdir(path)]\n",
    "\n",
    "x_train_imgname = filename(train_dir) \n",
    "x_test_imgname = filename(test_dir)\n",
    "y_train_label = category(train_dir)\n",
    "\n",
    "train_image_df = pd.DataFrame({ 'filename': x_train_imgname, 'category': y_train_label})\n",
    "submission_image_df = pd.DataFrame({'filename': x_test_imgname})\n",
    "\n",
    "print(train_image_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÕES AUXILIARES\n",
    "\n",
    "def img_path(directory):\n",
    "    ''' \n",
    "    Esta função extrai os IDs das imagens, categoria e caminho do diretório.\n",
    "    Input:\n",
    "    directiory: Local das imagens\n",
    "    Return:\n",
    "    ID_no: Lista dos IDs das imagens\n",
    "    Paths: Lista do caminho das imagens\n",
    "    cate: Lista das categorias\n",
    "    '''\n",
    "    paths = []\n",
    "    cate = []\n",
    "    ID_no = []\n",
    "    for file in os.listdir(directory):\n",
    "        path = os.path.join(directory, file)\n",
    "        paths.append(path)\n",
    "        cate.append(file.split('.')[0])\n",
    "        ID_no.append(file.split('.')[1])\n",
    "    return ID_no, paths, cate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def showImages(data,num_row  = 3,num_col =  3, name = 'any', subtitle = 'off'):\n",
    "    \"\"\" Esta função cria uma grade de imagens do conjunto de dados.\n",
    "    Imagens embaralhadas serão exibidas.\n",
    "    \n",
    "    Input: \n",
    "    num_row: default: 3, numero de linhas em uma grade\n",
    "    num_col: default:3, numero de colunas em uma grade\n",
    "    data: Dataframe de caminhos \n",
    "    name:  padrão 'qualquer', leva: gato, cachorro, qualquer outra coisa daria ambos\n",
    "    subtitle: exibe o número de identificação de cada imagem, padrão: 'off', leva: 'on' e 'off'\n",
    "    Return: None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Pequena classificação de dados\n",
    "    cat_df,dog_df = data[data['Category'] == 'cat'], data[data['Category'] == 'dog']\n",
    "\n",
    "    \n",
    "    if name == 'dog':\n",
    "        X, Y  = dog_df['img_paths'], dog_df['ID_no']\n",
    "    elif name == 'cat':\n",
    "        X, Y  = cat_df['img_paths'], cat_df['ID_no']     \n",
    "    else:\n",
    "        X, Y  = data['img_paths'], data['ID_no']     # poderia usar try e except, mas vamos nos ater ao código mínimo\n",
    "\n",
    "    (X_rand, Y_rand) = shuffle(X, Y)\n",
    "    \n",
    "    # mostrando as imagens com matplotlib \n",
    "    \n",
    "    fig, ax = plt.subplots(num_row,num_col,figsize = (12,12), dpi = 100)\n",
    "    fig.patch.set_facecolor('#f5f6f6')\n",
    "    axes = ax.ravel()\n",
    "    \n",
    "    for idx,ax  in enumerate(axes):\n",
    "        x = load_img(X_rand.iloc[idx],target_size= (125, 125))\n",
    "        ax.imshow(x)\n",
    "        if subtitle == 'on':\n",
    "            ax.set_title(\"{}\".format(Y_rand.iloc[idx]))\n",
    "        else:\n",
    "            ax.set_title('')\n",
    "        ax.axis('off')\n",
    "        plt.subplots_adjust(wspace =0)\n",
    "        del x\n",
    "    #fig.tight_layout()\n",
    "    \n",
    "    fig.text(0.1,0.93, '{}s da base de treinamento'.format(name.capitalize()),{'fontfamily':'serif','size':18,'weight':'bold'})\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando a função acima sobre o conjunto de dados de testes\n",
    "ID_no, img_paths, train_images = img_path(train_dir)\n",
    "\n",
    "print('\\n' + 'Dataframe está sendo criado para visualização de imagens de treinamento em uma grade...' + '\\n' )\n",
    "#creando novo dataframe para visualização de dados\n",
    "\n",
    "visual_df = pd.DataFrame({'ID_no':ID_no,'Category':train_images, 'img_paths': img_paths})\n",
    "\n",
    "print(visual_df.head(5))\n",
    "\n",
    "print('\\n' + 'Feito!' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d71601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZANDO ALGUNS CÃES DO DATASET DE TREINAMENTO\n",
    "\n",
    "showImages(visual_df,5,5, name = 'dog', subtitle = 'off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZANDO ALGUNS GATOS DO DATASET DE TREINAMENTO\n",
    "\n",
    "showImages(visual_df,5,5, name = 'cat', subtitle = 'off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDINDO OS DADOS ENTRE UMA BASE DE TREINAMENTO E TESTES\n",
    "train_valid_df, test_df = train_test_split(train_image_df, test_size = 0.04)\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size = 0.2)\n",
    "\n",
    "train_images = train_df.shape[0]\n",
    "valid_images = valid_df.shape[0]\n",
    "holdon_images = test_df.shape[0]\n",
    "test_images = submission_image_df.shape[0]\n",
    "\n",
    "print('\\n' + 'Numero de imagens de treinamento: ' + str(train_images))\n",
    "print('\\n' +  'Numero de imagens de validação: ' + str(valid_images))\n",
    "print('\\n' +  'Numero de imagens de espera: ' + str(holdon_images))\n",
    "print('\\n' + 'Numero de imagens de testes: ' +str(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISANDO A DISTRIBUIÇÃO DAS IMAGENS\n",
    "\n",
    "fig = plt.figure(figsize =(8,8), dpi = 100)\n",
    "fig.patch.set_facecolor('#f5f6f6')\n",
    "gs = fig.add_gridspec(10,10)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[2:5,1:5])\n",
    "ax1 = fig.add_subplot(gs[2:5,6:10])\n",
    "ax2 = fig.add_subplot(gs[6:9,3:7])\n",
    "\n",
    "\n",
    "axes = [ax0,ax1,ax2]\n",
    "data  = [train_df['category'] ,  valid_df['category'], test_df['category']]\n",
    "labels = ['Base de Treino','Base de Validação','Base de Testes']\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_facecolor('#f5f6f6')\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    for loc in ['left','right','top','bottom']:\n",
    "        ax.spines[loc].set_visible(False)\n",
    "    \n",
    "for ax,df, label in zip(axes,data,labels):\n",
    "    sns.countplot(df, ax = ax, palette = ['#36609A','#FFCE30'], alpha =1)\n",
    "    ax.set_xlabel(xlabel = ' ')\n",
    "    for pa in ax.patches: \n",
    "        ax.text(pa.get_x(), pa.get_height(),'{}'.format(pa.get_height()), **{'fontfamily':'serif', 'size':10, 'weight':'bold'}, alpha = 1)\n",
    "\n",
    "    ax.text(0,0,label,**{'fontfamily':'serif', 'size':10, 'weight':'bold'})\n",
    "\n",
    "fig.text(0.1,0.82, 'Distribuição das imagens',{'fontfamily':'serif','size':18,'weight':'bold'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c926b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICAÇÃO UTILIZANDO VANILA CNN\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 128\n",
    "\n",
    "# iteradores de dataframe sem adição de dados\n",
    "\n",
    "train_map = ImageDataGenerator()\n",
    "valid_map = ImageDataGenerator()\n",
    "test_map =  ImageDataGenerator()\n",
    "        \n",
    "#Criando iteradores de dataframe para ajuste\n",
    "vani_train_data = train_map.flow_from_dataframe(\n",
    "            train_df,train_dir,\n",
    "            x_col = 'filename',\n",
    "            y_col = 'category',\n",
    "            target_size = (img_size, img_size),\n",
    "            batch_size = batch_size,\n",
    "            class_mode = 'categorical')\n",
    "\n",
    "vani_valid_data = valid_map.flow_from_dataframe(\n",
    "             valid_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = 'category',\n",
    "             target_size = (img_size, img_size),\n",
    "             batch_size = batch_size,\n",
    "             class_mode = 'categorical')\n",
    "\n",
    "\n",
    "vani_test_data = test_map.flow_from_dataframe(\n",
    "             test_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = None,\n",
    "             target_size = (img_size, img_size),\n",
    "             batch_size = batch_size,\n",
    "             class_mode = None,\n",
    "             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c07cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTRUINDO O MODELO\n",
    "\n",
    "vani_model = Sequential()\n",
    "vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))\n",
    "vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Dropout(0.3))\n",
    "\n",
    "vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Dropout(0.3))\n",
    "\n",
    "vani_model.add(Flatten())\n",
    "\n",
    "vani_model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "vani_model.add(Dropout(0.5))\n",
    "\n",
    "vani_model.add(Dense(2, activation = 'softmax')) # 2 PORQUE NÓS TEMOS AS CLASSES DE CACHORRO E GATO\n",
    "\n",
    "vani_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREINANDO O MODELO\n",
    "\n",
    "#compilando modelo com loss, opt, metricas\n",
    "loss = 'categorical_crossentropy'\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.0001,beta_1=0.9, beta_2=0.999,epsilon=1e-07)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "vani_model.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "\n",
    "# ajustar (fitting) o modelo para o conjunto de dados de treinamento\n",
    "vani_history = vani_model.fit(vani_train_data, epochs = 10,\n",
    "                          validation_data = vani_valid_data,\n",
    "                          validation_steps= valid_images//batch_size,\n",
    "                          steps_per_epoch= train_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966240c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos representar graficamente a mudança do modelo Vanila CNN na perda e precisão com as épocas\n",
    "\n",
    "# paleta de cores\n",
    "colors = ['#EF7D71','#41ABD7','#36609A','#FFCE30','#194350']\n",
    "\n",
    "fig,ax  = plt.subplots(2,1, figsize =(8,8), dpi = 100)\n",
    "fig.patch.set_facecolor('#f5f6f6')\n",
    "\n",
    "axes  = ax.ravel()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_facecolor('#f5f6f6')\n",
    "    for loc in ['right','top',]:\n",
    "        ax.spines[loc].set_visible(False)\n",
    "        \n",
    "hist1 = vani_history.history\n",
    "Epochs =  range(len(hist1['loss']))\n",
    "\n",
    "## loss plot\n",
    "sns.lineplot(x = Epochs, y = hist1['val_loss'],  ax = axes[0], linewidth = 4, color = colors[3])\n",
    "sns.lineplot(x = Epochs, y = hist1['loss'], ax  = axes[0], linewidth =4,  color = colors[4])\n",
    "\n",
    "\n",
    "axes[0].text(Epochs[-1]+0.25,hist1['val_loss'][-1],'Validation Loss',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[3]})\n",
    "axes[0].text(Epochs[-1]+0.25,hist1['loss'][-1] ,'Training Loss',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[4]})\n",
    "\n",
    "\n",
    "# accuracy plot\n",
    "sns.lineplot(x = Epochs, y = hist1['val_accuracy'],ax = axes[1],linewidth = 4, color = colors[3])\n",
    "sns.lineplot(x = Epochs, y = hist1['accuracy'],ax = axes[1],linewidth =4,  color = colors[4])\n",
    "axes[1].text(Epochs[-1]+0.25,hist1['val_accuracy'][-1],'Validation Accuracy',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[3]})\n",
    "axes[1].text(Epochs[-1]+0.25,hist1['accuracy'][-1] ,'Training Accuracy',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[4]})\n",
    "\n",
    "\n",
    "fig.text(0,1.06, 'Vanilla Loss and Accuracy ',{'fontfamily':'serif', 'size':18, 'weight':'bold'})\n",
    "fig.text(0,1.01, '''Claramente temos um overfitting com este modelo.''',{'fontfamily':'serif', 'size':12})\n",
    "\n",
    "plt.tight_layout(h_pad = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APLICANDO A CONFUSION MATRIX NO MODELO CNN VANILLA\n",
    "\n",
    "vani_pred = vani_model.predict_generator(vani_test_data)\n",
    "test_df['vani_pred'] = np.argmax(vani_pred, axis = -1)\n",
    "labels = dict((v,k) for k,v in vani_train_data.class_indices.items())\n",
    "\n",
    "test_df['vani_pred'] = test_df['vani_pred'].map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "\n",
    "\n",
    "    # CÓDIGO PARA GERAR TEXTO DENTRO DE CADA QUADRADO\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CÓDIGO PARA GERAR ESTATÍSTICAS RESUMIDAS E TEXTO PARA ESTATÍSTICAS RESUMIDAS\n",
    "    if sum_stats:\n",
    "        #A precisão é a soma da diagonal dividida pelo total de observações\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #se for uma matriz de confusão binária, mostre mais algumas estatísticas\n",
    "        if len(cf)==2:\n",
    "            #Métricas para matrizes de confusão binárias\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # AJUSTE OS PARÂMETROS DA FIGURA DE ACORDO COM OUTROS ARGUMENTOS\n",
    "    if figsize==None:\n",
    "        #Obtenha o tamanho padrão da figura se não for definido\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Não mostrar categorias se xyticks for False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # FAÇA A VISUALIZAÇÃO DO HEATMAP\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.patch.set_facecolor('#f5f6f6')\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",linewidths = 1,square = True,linecolor= '#f5f6f6',\n",
    "                cmap=cmap,cbar=cbar,annot_kws={'fontfamily':'serif','size':18,'weight':'bold'},\n",
    "                xticklabels=categories,\n",
    "                yticklabels=categories,)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label', **{'fontfamily':'serif','size':12,'weight':'bold'})\n",
    "        plt.xlabel('Predicted label' + stats_text,**{'fontfamily':'serif','size':12,'weight':'bold'})\n",
    "    else:\n",
    "        plt.xlabel(stats_text,**{'fontfamily':'serif','size':12,'weight':'bold'})\n",
    "    \n",
    "    plt.gca().set_xticklabels(categories, {'fontfamily':'serif','size':16,'weight':'bold'})\n",
    "    plt.gca().set_yticklabels(categories, {'fontfamily':'serif','size':16,'weight':'bold'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c053627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vani_cf_matrix = confusion_matrix(test_df['category'],test_df['vani_pred'])\n",
    "my_cols = [colors[3],colors[2]]\n",
    "\n",
    "labels = [ 'True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Cat', 'Dog']\n",
    "make_confusion_matrix(vani_cf_matrix,figsize = (10,5),\n",
    "                      group_names=labels,cbar = False,cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",my_cols),\n",
    "                      categories=categories, \n",
    "                      title = 'Vanila CNN matriz de confusão')\n",
    "\n",
    "plt.gcf().text(0,1.1,'Vanilla CNN Avaliação dos dados de teste',{'fontfamily':'serif', 'size':24,  'color':'black', 'weight':'bold'})\n",
    "plt.gcf().text(0,0.995,\"\"\"Parece que até a CNN vanilla fez um bom trabalho considerando os parâmetros treinados.\n",
    "Vamos ver como o modelo pré-treinado faz o trabalho ...\"\"\",{'fontfamily':'serif', 'size':14,  'color':'black', })\n",
    "\n",
    "plt.gcf().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70910abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos codificar a função auxiliar para visualização do aumento da imagem ...\n",
    "\n",
    "def data_argumentation_show(n, grid_size):\n",
    "    sample_aug_map = ImageDataGenerator(\n",
    "            #zoom_range = 0.1,\n",
    "            rotation_range = 25,\n",
    "            horizontal_flip = True,\n",
    "            height_shift_range =0.2,\n",
    "            width_shift_range = 0.2,\n",
    "            fill_mode='nearest',\n",
    "            rescale = 1/255)\n",
    "    sample_data = sample_aug_map.flow_from_dataframe(\n",
    "            (train_df.sample(n)),\n",
    "            train_dir,\n",
    "            x_col = 'filename',\n",
    "            y_col = 'category',\n",
    "            target_size = (img_size, img_size),\n",
    "            class_mode = 'categorical')\n",
    "  \n",
    "  #subplot grid \n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    fig.patch.set_facecolor('#f5f6f6')\n",
    "    for i in range(0,grid_size*grid_size):\n",
    "        plt.subplot(grid_size,grid_size, i+1)\n",
    "        for x,y in sample_data:\n",
    "            img = x[0]\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            break\n",
    "            plt.tight_layout()\n",
    "            del img\n",
    "    fig.show()\n",
    "     \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulalizar o efeito da argumentação de dados\n",
    "# selecionar o número de amostras para o argumento----> n = \n",
    "# número total de argumentação é grid_Size**2\n",
    "\n",
    "data_argumentation_show(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f98a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de definição da taxa de aprendizagem decadente ...\n",
    "\n",
    "print('\\nDefinindo uma taxa de aprendizagem para a programação da taxa de aprendizagem\\n')\n",
    "epoch = 50\n",
    "learning_rate = 3e-5 \n",
    "lr_start = 0.00000001\n",
    "lr_min = 0.000001\n",
    "lr_max = 3e-5 \n",
    "lr_rampup_epochs = 1\n",
    "lr_sustain_epochs = 1\n",
    "lr_exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < lr_rampup_epochs:\n",
    "        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "        lr = lr_max\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed096387",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "epochs_range = [i for i in range(50 if epochs<50 else epochs)]\n",
    "learn_rate = [lrfn(x) for x in epochs_range]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (10,5))\n",
    "fig.patch.set_facecolor('#f5f6f6')\n",
    "ax.set_facecolor('#f5f6f6')\n",
    "\n",
    "for loc in ['right','top',]:\n",
    "    ax.spines[loc].set_visible(False)\n",
    "\n",
    "ax.plot(epochs_range, learn_rate, linewidth = 4, color= colors[2]) \n",
    "plt.xlabel('Range of epochs',{'fontfamily':'serif', 'size':14,  'color':'black', 'weight':'bold'})\n",
    "plt.ylabel('Learning rate in 10^-5',{'fontfamily':'serif', 'size':14,  'color':'black', 'weight':'bold'})\n",
    "\n",
    "\n",
    "plt.gcf().text(0,1.06,'Learning Rate Schedule',{'fontfamily':'serif', 'size':24,  'color':'black', 'weight':'bold'})\n",
    "plt.gcf().text(0,0.975,\"\"\"Definido inicialmente uma taxa de aprendizagem que aumenta linearmente de 1e-08 para 3e-5 e mais tarde\n",
    "diminui exponencialmente de 3e-5 para 1e-6\"\"\",{'fontfamily':'serif', 'size':14,  'color':'black', })\n",
    "\n",
    "plt.gcf().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICAÇÃO COM ResNet50\n",
    "\n",
    "# Preparação de dados para aumento de imagem com ImageDataGenerator\n",
    "\n",
    "# usando aumento de dados padrão\n",
    "\n",
    "train_aug_map = ImageDataGenerator(\n",
    "                    rotation_range=10,\n",
    "                    #zoom_range=0.1,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest',\n",
    "                    #width_shift_range=0.1,\n",
    "                    #height_shift_range=0.1,\n",
    "                    preprocessing_function = preprocess_input)\n",
    "res_train_data = train_aug_map.flow_from_dataframe(\n",
    "            train_df, train_dir,\n",
    "            x_col = 'filename',\n",
    "            y_col = 'category',\n",
    "            target_size = (img_size, img_size),\n",
    "            batch_size = batch_size,\n",
    "            class_mode = 'categorical')\n",
    "\n",
    "valid_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "res_valid_data = valid_aug_map.flow_from_dataframe(\n",
    "             valid_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = 'category',\n",
    "             target_size = (img_size, img_size),\n",
    "             batch_size = batch_size,\n",
    "             class_mode = 'categorical')\n",
    "\n",
    "#Dados de testes, reescalonamento de imagens\n",
    "\n",
    "test_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "res_test_data = test_aug_map.flow_from_dataframe(\n",
    "             test_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = None,\n",
    "             class_mode = None,\n",
    "             target_size = (img_size, img_size),\n",
    "             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construindo um modelo para transferência de aprendizagem em cima de um modelo ResNet50 pré-treinado...\n",
    "\n",
    "resNet = tf.keras.applications.ResNet50(weights = 'imagenet',\n",
    "                        include_top = False,\n",
    "                        input_shape = (224,224, 3))\n",
    "\n",
    "resNet.trainable = False # Camadas congeladas\n",
    "resNet_model = Sequential([\n",
    "        resNet,\n",
    "        Flatten(),\n",
    "        Dense(1024, activation = 'relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(2, activation = 'softmax')])\n",
    "     \n",
    "optimizer = optimizers.Adam(1e-5)\n",
    "\n",
    "resNet_model.summary()\n",
    "#plot_model(resNet_model, to_file='resNet_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f90e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o fator de parada antecipada e a programação da taxa de aprendizagem\n",
    "\n",
    "earlystop = EarlyStopping(patience= 5)\n",
    "    \n",
    "lr_callback = LearningRateScheduler(lrfn, verbose = True)\n",
    "\n",
    "callbacks = [earlystop, lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea55775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos treinar e validar o modelo ResNet50 pré-treinado para as camadas superiores \n",
    "\n",
    "resNet_model.compile(optimizer = optimizer,\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "resnet_history = resNet_model.fit_generator(res_train_data, epochs = 10,\n",
    "                          validation_data = res_valid_data,\n",
    "                          validation_steps= valid_images//batch_size,\n",
    "                          steps_per_epoch= train_images//batch_size,\n",
    "                          callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548624ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando o resultado do modelo ResNet\n",
    "\n",
    "fig,ax  = plt.subplots(2,1, figsize =(8,8), dpi = 100)\n",
    "fig.patch.set_facecolor('#f5f6f6')\n",
    "\n",
    "axes  = ax.ravel()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_facecolor('#f5f6f6')\n",
    "    for loc in ['right','top',]:\n",
    "        ax.spines[loc].set_visible(False)\n",
    "        \n",
    "hist2 = resnet_history.history\n",
    "Epochs =  range(len(hist2['loss']))\n",
    "\n",
    "## loss plot\n",
    "sns.lineplot(x = Epochs, y = hist2['val_loss'],  ax = axes[0], linewidth = 4, color = colors[3])\n",
    "sns.lineplot(x = Epochs, y = hist2['loss'], ax  = axes[0], linewidth =4,  color = colors[4])\n",
    "\n",
    "\n",
    "axes[0].text(Epochs[-1]+0.25,hist2['val_loss'][-1],'Validation Loss',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[3]})\n",
    "axes[0].text(Epochs[-1]+0.25,hist2['loss'][-1]-0.1 ,'Training Loss',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[4]})\n",
    "\n",
    "\n",
    "# accuracy plot\n",
    "sns.lineplot(x = Epochs, y = hist2['val_accuracy'],ax = axes[1],linewidth = 4, color = colors[3])\n",
    "sns.lineplot(x = Epochs, y = hist2['accuracy'],ax = axes[1],linewidth =4,  color = colors[4])\n",
    "axes[1].text(Epochs[-1]+0.25,hist2['val_accuracy'][-1]-0.04,'Validation Accuracy',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[3]})\n",
    "axes[1].text(Epochs[-1]+0.25,hist2['accuracy'][-1] ,'Training Accuracy',{'fontfamily':'serif', 'size':12, 'weight':'bold','color':colors[4]})\n",
    "\n",
    "\n",
    "fig.text(0,1.06, 'ResNet Loss e Accuracy ',{'fontfamily':'serif', 'size':18, 'weight':'bold'})\n",
    "fig.text(0,1.01, '''Como esperado, a aprendizagem por transferência fez um bom trabalho com quase nenhuma\n",
    "diferença entre validation, training loss e accuracies.''',{'fontfamily':'serif', 'size':12})\n",
    "        \n",
    "plt.tight_layout(h_pad = 5)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos ver as prediçõs desse modelo aplicando a matriz de confusão\n",
    "\n",
    "res_pred = resNet_model.predict_generator(res_test_data)\n",
    "test_df['res_pred'] = np.argmax(res_pred, axis = -1)\n",
    "labels = dict((v,k) for k,v in res_train_data.class_indices.items())\n",
    "\n",
    "test_df['res_pred'] = test_df['res_pred'].map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cf_matrix = confusion_matrix(test_df['category'],test_df['res_pred'])\n",
    "my_cols = [colors[3],colors[2]]\n",
    "\n",
    "labels = [ 'True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Cat', 'Dog']\n",
    "make_confusion_matrix(res_cf_matrix,figsize = (10,5),\n",
    "                      group_names=labels,cbar = False,cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",my_cols),\n",
    "                      categories=categories, \n",
    "                      title = 'Vanila CNN comfusion matrix')\n",
    "\n",
    "plt.gcf().text(0,1.1,'ResNet - Avaliação dos dados de teste',{'fontfamily':'serif', 'size':24,  'color':'black', 'weight':'bold'})\n",
    "plt.gcf().text(0,0.995,\"\"\"Está claro que o modelo resnet fez um ótimo trabalho.\"\"\",{'fontfamily':'serif', 'size':14,  'color':'black', })\n",
    "\n",
    "plt.gcf().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previsões finais no conjunto de teste\n",
    "#Preparação de dados de teste final para vanilla e resnet para previsões finais\n",
    "\n",
    "# gerar um iterador de dataframe para o conjunto de dados de teste\n",
    "\n",
    "vani_sub_aug_map = ImageDataGenerator()\n",
    "res_sub_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "vani_sub_data = vani_sub_aug_map.flow_from_dataframe(\n",
    "             submission_image_df, test_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = None,\n",
    "             class_mode = None,\n",
    "             target_size = (img_size, img_size),\n",
    "             shuffle = False)\n",
    "\n",
    "\n",
    "res_sub_data = res_sub_aug_map.flow_from_dataframe(\n",
    "             submission_image_df, test_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = None,\n",
    "             class_mode = None,\n",
    "             target_size = (img_size, img_size),\n",
    "             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo previsões finais com as CNNs resnet e vanilla com os dados de teste\n",
    "\n",
    "vani_pred_sub = vani_model.predict_generator(vani_sub_data)\n",
    "submission_image_df['vani_pred_sub'] = np.argmax(vani_pred_sub, axis = -1)\n",
    "labels = dict((v,k) for k,v in res_train_data.class_indices.items())\n",
    "submission_image_df['vani_pred_sub'] = submission_image_df['vani_pred_sub'].map(labels)\n",
    "\n",
    "\n",
    "res_pred_sub = resNet_model.predict_generator(res_sub_data)\n",
    "submission_image_df['res_pred_sub'] = np.argmax(res_pred_sub, axis = -1)\n",
    "labels = dict((v,k) for k,v in res_train_data.class_indices.items())\n",
    "submission_image_df['res_pred_sub'] = submission_image_df['res_pred_sub'].map(labels)\n",
    "\n",
    "print(submission_image_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3948af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos ver como nossas previsões são feitas nos dados de teste por ambas as redes\n",
    "\n",
    "pred_sample = submission_image_df.sample(18)\n",
    "pred_sample.reset_index(drop = True, inplace = True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,24))\n",
    "fig.patch.set_facecolor('#f5f6f6')\n",
    "\n",
    "for index, row in pred_sample.iterrows():\n",
    "    filename = row['filename']\n",
    "    vani_pred = row['vani_pred_sub']\n",
    "    res_pred = row['res_pred_sub']\n",
    "    img = load_img( test_dir + filename, target_size= (img_size, img_size))\n",
    "    plt.subplot(6,3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "    plt.text(130, 175, 'vanila_pred: {}'.format(vani_pred), color='lightgreen',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n",
    "    plt.text(130, 200, 'resNet_pred: {}'.format(res_pred), color='red',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n",
    "    #plt.title(filename.split('.')[0])\n",
    "    del img\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust( wspace=0, hspace= 1)\n",
    "fig.text(0,1, 'Rótulos dos dados de teste',{'fontfamily':'serif','size':24,'weight':'bold'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60040a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
